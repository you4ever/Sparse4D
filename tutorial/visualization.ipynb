{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb7b034a-deee-49fe-b9b7-d15aeec94841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "if cwd.endswith(\"tutorial\"):\n",
    "    os.chdir(\"../\")\n",
    "\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from mmcv import Config\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmcv.parallel import scatter\n",
    "from mmcv.cnn.utils.flops_counter import add_flops_counting_methods\n",
    "\n",
    "from projects.mmdet3d_plugin.datasets.builder import build_dataloader\n",
    "from projects.mmdet3d_plugin.datasets.utils import draw_lidar_bbox3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6defc87f-f9c3-4b4e-8821-73a524d8032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id = 0\n",
    "config = \"sparse4dv3_temporal_r50_1x8_bs6_256x704\"\n",
    "checkpoint = \"ckpt/sparse4dv3_temporal_r50_1x8_bs6_256x704.pth\"\n",
    "# checkpoint = \"ckpt/sparse4dv3_r50.pth\"\n",
    "\n",
    "cfg = Config.fromfile(f\"projects/configs/{config}.py\")\n",
    "# cfg.model[\"use_deformable_func\"] = False\n",
    "# cfg.model[\"head\"][\"deformable_model\"][\"use_deformable_func\"] = False\n",
    "img_norm_mean = np.array(cfg.img_norm_cfg[\"mean\"])\n",
    "img_norm_std = np.array(cfg.img_norm_cfg[\"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "803548d7-d7cf-4f27-afca-26b8e5268b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'version': 'v1.0-trainval'}\n",
      "WARNING!!!!, Only can be used for obtain inference speed!!!!\n"
     ]
    }
   ],
   "source": [
    "dataset = build_dataset(cfg.data.val)\n",
    "dataloader = build_dataloader(\n",
    "    dataset,\n",
    "    samples_per_gpu=1,\n",
    "    workers_per_gpu=0,\n",
    "    dist=False,\n",
    "    shuffle=False,\n",
    ")\n",
    "data_iter = dataloader.__iter__()\n",
    "data = next(data_iter)\n",
    "data = scatter(data, [gpu_id])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0584e65d-f51f-4106-a1d8-87b410d29566",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_detector(cfg.model)\n",
    "model = model.cuda(gpu_id)\n",
    "_ = model.load_state_dict(torch.load(checkpoint)[\"state_dict\"], strict=False)\n",
    "model = model.eval()\n",
    "# assert model.use_deformable_func, \"Please compile deformable aggregation first !!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7354db72-6788-4713-86fd-2d57970f08a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved to output_detections_video_pyav.mp4\n",
      "Frames saved to output/\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import av  # PyAV library\n",
    "from mmcv.parallel import scatter\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = 'output'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Class names and corresponding color mapping in RGB\n",
    "CLASSES = (\n",
    "    \"car\",\n",
    "    \"truck\",\n",
    "    \"construction_vehicle\",\n",
    "    \"bus\",\n",
    "    \"trailer\",\n",
    "    \"barrier\",\n",
    "    \"motorcycle\",\n",
    "    \"bicycle\",\n",
    "    \"pedestrian\",\n",
    "    \"traffic_cone\",\n",
    ")\n",
    "ID_COLOR_MAP = [\n",
    "    (59, 59, 238),   # car - blue\n",
    "    (0, 255, 0),     # truck - green\n",
    "    (255, 0, 0),     # construction_vehicle - red\n",
    "    (255, 255, 0),   # bus - yellow\n",
    "    (0, 255, 255),   # trailer - cyan\n",
    "    (255, 0, 255),   # barrier - magenta\n",
    "    (255, 255, 255), # motorcycle - white\n",
    "    (255, 127, 0),   # bicycle - orange\n",
    "    (71, 130, 255),  # pedestrian - light blue\n",
    "    (127, 127, 0),   # traffic_cone - olive\n",
    "]\n",
    "\n",
    "# Convert RGB colors to BGR for OpenCV compatibility (for both legend and bounding boxes)\n",
    "def convert_rgb_to_bgr(color_map):\n",
    "    return [(b, g, r) for (r, g, b) in color_map]\n",
    "\n",
    "# Apply BGR conversion to the ID_COLOR_MAP\n",
    "ID_COLOR_MAP_BGR = convert_rgb_to_bgr(ID_COLOR_MAP)\n",
    "\n",
    "# Function to draw the legend on an image using BGR colors\n",
    "def draw_legend(image):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    font = ImageFont.load_default()  # Use default font\n",
    "    x, y = 10, 10  # Starting position of the legend\n",
    "    for i, (class_name, color) in enumerate(zip(CLASSES, ID_COLOR_MAP)):\n",
    "        draw.rectangle([x, y + i * 20, x + 15, y + 15 + i * 20], fill=color)\n",
    "        draw.text((x + 20, y + i * 20), class_name, fill=(255, 255, 255), font=font)\n",
    "    return image\n",
    "\n",
    "# Initialize variables to store frame dimensions (extracted dynamically)\n",
    "frame_width = None\n",
    "frame_height = None\n",
    "\n",
    "# Set up video writer using PyAV\n",
    "output_video_path = \"output_detections_video_pyav.mp4\"\n",
    "fps = 5  # Frames per second\n",
    "\n",
    "# Reset instance bank\n",
    "model.head.instance_bank.reset()\n",
    "\n",
    "# Iterate over the dataset and save each frame\n",
    "for i, data in enumerate(data_iter):\n",
    "    # if i >= 100:\n",
    "    #     break\n",
    "    data = scatter(data, [gpu_id])[0]\n",
    "    \n",
    "    # Feature extraction and model output\n",
    "    feature_maps = model.extract_feat(data[\"img\"], metas=data)\n",
    "    model_outs = model.head(feature_maps, data)\n",
    "    \n",
    "    # Decode predicted bounding boxes\n",
    "    pred_bbox3d = model.head.decoder.decode_box(model_outs[\"prediction\"][-1][0])\n",
    "    \n",
    "    # Extract class scores and find the predicted class for each instance\n",
    "    class_scores = model_outs['classification'][-1].max(dim=-1)[0][0].sigmoid()  # Extract confidence scores\n",
    "    predicted_classes = model_outs['classification'][-1].argmax(dim=-1)[0]  # Extract predicted class per instance\n",
    "    \n",
    "    # Apply confidence threshold\n",
    "    mask = class_scores > 0.35\n",
    "    num_det = mask.sum()\n",
    "\n",
    "    # Prepare the raw image and correct color scaling\n",
    "    raw_imgs = data[\"img\"][0].permute(0, 2, 3, 1).cpu().numpy()\n",
    "    raw_imgs = (raw_imgs * img_norm_std + img_norm_mean).astype(np.uint8)  # Ensure it's in the uint8 range for proper color display\n",
    "\n",
    "    # Assign colors to bounding boxes based on predicted classes (using BGR for OpenCV compatibility)\n",
    "    colors = [ID_COLOR_MAP[class_idx.item() % len(ID_COLOR_MAP)] for class_idx in predicted_classes[mask]]\n",
    "    \n",
    "    # Draw 3D bounding boxes on the image with class-based colors\n",
    "    img_with_detections = draw_lidar_bbox3d(\n",
    "        pred_bbox3d[mask],\n",
    "        raw_imgs, data[\"projection_mat\"][0],\n",
    "        color=colors  # Assign the color for each detected box (BGR)\n",
    "    )\n",
    "\n",
    "    # Convert to PIL Image for further drawing (legend and boxes)\n",
    "    img_rgb = Image.fromarray(img_with_detections.astype(np.uint8))\n",
    "\n",
    "    # Draw the color legend on the image (now using BGR colors)\n",
    "    img_rgb = draw_legend(img_rgb)\n",
    "\n",
    "    # Dynamically set frame dimensions based on img_with_detections\n",
    "    if frame_width is None or frame_height is None:\n",
    "        frame_height, frame_width = img_rgb.size[1], img_rgb.size[0]\n",
    "\n",
    "        # Initialize PyAV container and video stream after getting dimensions\n",
    "        container = av.open(output_video_path, mode='w')\n",
    "        stream = container.add_stream('mpeg4', rate=fps)\n",
    "        stream.width = frame_width\n",
    "        stream.height = frame_height\n",
    "        stream.pix_fmt = 'yuv420p'  # Set pixel format for compatibility\n",
    "\n",
    "        # Set higher quality parameters\n",
    "        stream.bit_rate = 5000000  # 5 Mbps (adjust as needed for higher quality)\n",
    "        stream.options = {'qscale:v': '2'}  # Lower qscale = higher quality\n",
    "\n",
    "    # Save the frame as an image for debugging\n",
    "    frame_path = os.path.join(output_dir, f\"frame_{i:03d}.png\")\n",
    "    img_rgb.save(frame_path)\n",
    "\n",
    "    # Convert the image to a PyAV video frame\n",
    "    frame = av.VideoFrame.from_image(img_rgb)\n",
    "\n",
    "    # Encode the frame\n",
    "    for packet in stream.encode(frame):\n",
    "        container.mux(packet)\n",
    "\n",
    "# Finalize the video stream (flush remaining frames)\n",
    "for packet in stream.encode():\n",
    "    container.mux(packet)\n",
    "\n",
    "# Close the PyAV container\n",
    "container.close()\n",
    "\n",
    "print(f\"Video saved to {output_video_path}\")\n",
    "print(f\"Frames saved to {output_dir}/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad611dc4-f53d-42ce-a410-fc2f520368c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalize the video stream (flush remaining frames)\n",
    "for packet in stream.encode():\n",
    "    container.mux(packet)\n",
    "\n",
    "# Close the PyAV container\n",
    "container.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb5aff8-c1aa-4882-9cbe-665c56cd318a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
